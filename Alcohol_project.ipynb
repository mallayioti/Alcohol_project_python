{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION MODELS FOR THE PREDICTION OF THE ALCOHOL DIFUSSION MODEL PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates=pd.read_csv('PersonLevel_Master_2-3-21_ES_Edited_Merged_SummStat.csv',index_col='ID_S')\n",
    "covariates.to_csv(\"CovariatesCopy.csv\",na_rep='NA')\n",
    "covariates_copy=pd.read_csv('CovariatesCopy.csv',index_col='ID_S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORE CATEGORICAL COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates['BIOSEX'].value_counts()\n",
    "covariates.BIOSEX[covariates['BIOSEX']=='female']=0\n",
    "covariates.BIOSEX[covariates['BIOSEX']=='male']=1\n",
    "covariates['BIOSEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates['ATE_C'].value_counts()\n",
    "covariates.ATE_C[covariates['ATE_C']=='8+ hours']=5\n",
    "covariates.ATE_C[covariates['ATE_C']=='6-7 hours']=4\n",
    "covariates.ATE_C[covariates['ATE_C']=='5-6 hours']=3\n",
    "covariates.ATE_C[covariates['ATE_C']=='4-5 hours']=2\n",
    "covariates.ATE_C[covariates['ATE_C']=='<4 hours']=1\n",
    "covariates.ATE_C[covariates['ATE_C']=='-99.00']=5\n",
    "covariates['ATE_C'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates['WATER_C'].value_counts()\n",
    "covariates.WATER_C[covariates['WATER_C']=='3+ hours']=4\n",
    "covariates.WATER_C[covariates['WATER_C']=='1-2 hours']=2\n",
    "covariates.WATER_C[covariates['WATER_C']=='2-3 hours']=3\n",
    "covariates.WATER_C[covariates['WATER_C']=='<1 hours']=1\n",
    "covariates['WATER_C'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSDERMAL ALCOHOL CONCENTRATION (TAC) RELATED COVARIATES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAC values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "data = scipy.io.loadmat('TAC_inter.mat')\n",
    "data_list = [[element for element in upperElement] for upperElement in data['TAC_inter']]\n",
    "TAC1_l=[]\n",
    "TAC2_l=[]\n",
    "TAC3_l=[]\n",
    "TAC4_l=[]\n",
    "for row in range(len(data_list)):\n",
    "    TAC1_l.append(data_list[row][0])\n",
    "    TAC2_l.append(data_list[row][1])\n",
    "    TAC3_l.append(data_list[row][2])\n",
    "    TAC4_l.append(data_list[row][3])\n",
    "newData = list(zip(TAC1_l, TAC2_l, TAC3_l, TAC4_l))\n",
    "columns = ['TAC1', 'TAC2','TAC3','TAC4']\n",
    "TAC_inter = pd.DataFrame(newData, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates.entry[covariates['entry'].notna()].astype(int)\n",
    "index = TAC_inter.index\n",
    "number_of_rows = len(index) \n",
    "for row in range(number_of_rows):\n",
    "    covariates.TAC1[covariates.entry==row+1]=TAC_inter.TAC1[row]\n",
    "    covariates.TAC2[covariates.entry==row+1]=TAC_inter.TAC2[row]\n",
    "    covariates.TAC3[covariates.entry==row+1]=TAC_inter.TAC3[row]\n",
    "    covariates.TAC4[covariates.entry==row+1]=TAC_inter.TAC4[row]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAC curve characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = covariates.index\n",
    "number_of_rows = len(index) \n",
    "for row in range(number_of_rows):\n",
    "    if covariates.arm[row]=='R':\n",
    "        covariates.Peak_TAC[row]= covariates.Peak_TACRarm[row]\n",
    "        covariates.TAC_Dur[row]= covariates.TACRarm_Dur[row]\n",
    "        covariates.TAC_AUC[row]= covariates.TACRarm_AUC[row]\n",
    "        covariates.TAC_0toPeak[row]= covariates.TACRarm_0toPeak[row]\n",
    "    elif covariates.arm[row]=='L':\n",
    "        covariates.Peak_TAC[row]= covariates.Peak_TACLarm[row]\n",
    "        covariates.TAC_Dur[row]= covariates.TACLarm_Dur[row]\n",
    "        covariates.TAC_AUC[row]= covariates.TACLarm_AUC[row]\n",
    "        covariates.TAC_0toPeak[row]= covariates.TACLarm_0toPeak[row]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAC curve slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('TAC_slopes.mat')\n",
    "slopes_list = [[element for element in upperElement] for upperElement in data['TAC_slopes']]\n",
    "asc_l=[]\n",
    "desc_l=[]\n",
    "for row in range(len(slopes_list)):\n",
    "    asc_l.append(slopes_list[row][0])\n",
    "    desc_l.append(slopes_list[row][1])\n",
    "newData = list(zip(asc_l, desc_l))\n",
    "columns = ['asc_slope', 'desc_slope']\n",
    "slopes = pd.DataFrame(newData, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates.entry[covariates['entry'].notna()].astype(int)\n",
    "index = slopes.index\n",
    "number_of_rows = len(index) \n",
    "for row in range(number_of_rows):\n",
    "    covariates.ASC[covariates.entry==row+1]=slopes.asc_slope[row]\n",
    "    covariates.DESC[covariates.entry==row+1]=slopes.desc_slope[row]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X AND y FOR : MODEL DEVELOPMENT / PREDICTION ON TEST SET / PREDICTION ON NEW INDIVIDUAL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=covariates.q1_2_A_D_1.iloc[22::].values\n",
    "y2=covariates.q2_2_A_D_1.iloc[22::].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_biv=list(zip(covariates['q1_2_A_D_1'],covariates['q2_2_A_D_1']))\n",
    "y_biv=y_biv[22::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Sess_Type','BIOSEX','Eth_Id_C','HT','WT','BF','VF','RM','WAIST','HIPS','AGE','mLALC','CAL_LUN','ATE_C','WATER_C','TLFB28d_F','TLFB90d_F','TLFB28d_B','TLFB90d_B','Peak_TAC','TAC_Dur','TAC_AUC','TAC_0toPeak','TAC1','TAC2','TAC3','TAC4']\n",
    "X=covariates[cols]\n",
    "X=X.iloc[22::,:]\n",
    "X.TAC4[X['TAC4'].isnull()]=0\n",
    "X.TAC3[X['TAC3'].isnull()]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind=covariates[(covariates.entry==34) | (covariates.entry==50) | (covariates.entry==82)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['entry','Sess_Type','BIOSEX','Eth_Id_C','HT','WT','BF','VF','RM','WAIST','HIPS','AGE','mLALC','CAL_LUN','ATE_C','WATER_C','TLFB28d_F','TLFB90d_F','TLFB28d_B','TLFB90d_B','Peak_TAC','TAC_Dur','TAC_AUC','TAC_0toPeak','TAC1','TAC2','TAC3','TAC4']\n",
    "X=covariates[cols]\n",
    "X=X.iloc[22::,:]\n",
    "X.TAC4[X['TAC4'].isnull()]=0\n",
    "X.TAC3[X['TAC3'].isnull()]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=covariates.q1_2_A_D_1.iloc[22::]\n",
    "y2=covariates.q2_2_A_D_1.iloc[22::]\n",
    "y1=y1.drop(test_ind).values\n",
    "y2=y2.drop(test_ind).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_biv=list(zip(y1,y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on new individual (first run model development)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : TAC_Dur = last nonzero obs time - first nonzero obs time,\n",
    "       TAC_0toPeak = peak time - last zero obs time (beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = {'Sess_Type':'First Single', 'BIOSEX':0, 'Eth_Id_C':'Asian', 'HT':166.5, 'WT':49.7, 'BF':19.8, 'VF':2, 'RM':1223,\n",
    "       'WAIST':64, 'HIPS':83.5, 'AGE':25, 'mLALC':119.95, 'CAL_LUN':587.13, 'ATE_C':5, 'WATER_C':4,\n",
    "       'TLFB28d_F':1, 'TLFB90d_F':2, 'TLFB28d_B':0, 'TLFB90d_B':0, 'Peak_TAC':0.019,\n",
    "       'TAC_Dur':117.2520, 'TAC_AUC':1.6219, 'TAC_0toPeak':106.2840, 'TAC1':0.0044, 'TAC2':0.0151, 'TAC3':0.0083, 'TAC4':0, 'ASC':0.0191, 'DESC':-0.0075}\n",
    "X = X.append(new, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HISTOGRAMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4, sharey=True, figsize=(15,15), tight_layout=True)\n",
    "\n",
    "axs[0,0].hist(X['HT'])\n",
    "axs[0,0].set_title('Height')\n",
    "axs[1,0].hist(X['WT'])\n",
    "axs[1,0].set_title('Weight')\n",
    "axs[2,0].hist(X['BF'])\n",
    "axs[2,0].set_title('Body Fat')\n",
    "axs[3,0].hist(X['TLFB28d_F'])\n",
    "axs[3,0].set_title('28d drink freq')\n",
    "axs[0,1].hist(X['VF'])\n",
    "axs[0,1].set_title('Visceral Fat')\n",
    "axs[0,2].hist(X['RM'])\n",
    "axs[0,2].set_title('Resting Metabolism')\n",
    "axs[0,3].hist(X['TLFB90d_F'])\n",
    "axs[0,3].set_title('90d drink freq')\n",
    "axs[1,1].hist(X['WAIST'])\n",
    "axs[1,1].set_title('Waist')\n",
    "axs[1,2].hist(X['HIPS'])\n",
    "axs[1,2].set_title('Hips')\n",
    "axs[1,3].hist(X['TLFB28d_B'])\n",
    "axs[1,3].set_title('28d binge days')\n",
    "axs[2,1].hist(X['CAL_LUN'])\n",
    "axs[2,1].set_title('Lunch Calories')\n",
    "axs[2,2].hist(X['ATE_C'])\n",
    "axs[2,2].set_title('Hours from eating')\n",
    "axs[2,3].hist(X['TLFB90d_B'])\n",
    "axs[2,3].set_title('90d binge days')\n",
    "axs[3,1].hist(X['AGE'])\n",
    "axs[3,1].set_title('Age')\n",
    "axs[3,2].hist(X['Sess_Type'])\n",
    "axs[3,2].set_title('Sess Type')\n",
    "axs[3,3].hist(X['Eth_Id_C'])\n",
    "axs[3,3].set_title('Ethnicity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SCALING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X['HT']= scaler.fit_transform(X['HT'].values.reshape(-1, 1))\n",
    "X['WT']= scaler.fit_transform(X['WT'].values.reshape(-1, 1))\n",
    "X['BF']= scaler.fit_transform(X['BF'].values.reshape(-1, 1))\n",
    "X['VF']= scaler.fit_transform(X['VF'].values.reshape(-1, 1))\n",
    "X['RM']= scaler.fit_transform(X['RM'].values.reshape(-1, 1))\n",
    "X['WAIST']= scaler.fit_transform(X['WAIST'].values.reshape(-1, 1))\n",
    "X['HIPS']= scaler.fit_transform(X['HIPS'].values.reshape(-1, 1))\n",
    "X['AGE']= scaler.fit_transform(X['AGE'].values.reshape(-1, 1))\n",
    "X['mLALC']= scaler.fit_transform(X['mLALC'].values.reshape(-1, 1))\n",
    "X['CAL_LUN']= scaler.fit_transform(X['CAL_LUN'].values.reshape(-1, 1))\n",
    "X['ATE_C']= scaler.fit_transform(X['ATE_C'].values.reshape(-1, 1))\n",
    "X['WATER_C']= scaler.fit_transform(X['WATER_C'].values.reshape(-1, 1))\n",
    "X['TLFB28d_F']= scaler.fit_transform(X['TLFB28d_F'].values.reshape(-1, 1))\n",
    "X['TLFB28d_B']= scaler.fit_transform(X['TLFB28d_B'].values.reshape(-1, 1))\n",
    "X['TLFB90d_F']= scaler.fit_transform(X['TLFB90d_F'].values.reshape(-1, 1))\n",
    "X['TLFB90d_B']= scaler.fit_transform(X['TLFB90d_B'].values.reshape(-1, 1))\n",
    "X['Peak_TAC']= scaler.fit_transform(X['Peak_TAC'].values.reshape(-1, 1))\n",
    "X['TAC_Dur']= scaler.fit_transform(X['TAC_Dur'].values.reshape(-1, 1))\n",
    "X['TAC_AUC']= scaler.fit_transform(X['TAC_AUC'].values.reshape(-1, 1))\n",
    "X['TAC_0toPeak']= scaler.fit_transform(X['TAC_0toPeak'].values.reshape(-1, 1))\n",
    "X['TAC1']= scaler.fit_transform(X['TAC1'].values.reshape(-1, 1))\n",
    "X['TAC2']= scaler.fit_transform(X['TAC2'].values.reshape(-1, 1))\n",
    "X['TAC3']= scaler.fit_transform(X['TAC3'].values.reshape(-1, 1))\n",
    "X['TAC4']= scaler.fit_transform(X['TAC4'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATEGORICAL FEATURES - ONE-HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('BIOSEX_1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTIONS ON SPECIFIC SESSIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sess_preds(X, y, X_test, x_columns, model):\n",
    "    X_train=X[x_columns]\n",
    "    X_test=X_test[x_columns]\n",
    "    mod = model.fit(X_train, y)\n",
    "    y_pred = mod.predict(X_test)\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X.loc[test_ind]\n",
    "X_test=X_test.drop('entry',axis=1)\n",
    "X=X.drop(test_ind)\n",
    "X=X.drop('entry',axis=1)\n",
    "x_columns=['HT', 'WT', 'BF', 'mLALC', 'ATE_C', 'TLFB90d_B', 'TAC_AUC', 'TAC_0toPeak', 'TAC3', 'Sess_Type_First Single', 'BIOSEX_0', 'Eth_Id_C_African/Af-Amer', 'Eth_Id_C_Caucasian', 'Eth_Id_C_Hispanic']\n",
    "model=LinearRegression()\n",
    "y=y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sess_preds(X, y, X_test, x_columns, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTIONS ON NEW INDIVIDUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_columns= ['WT', 'BF', 'VF', 'RM', 'TLFB90d_F', 'Peak_TAC', 'TAC_AUC', 'TAC1', 'TAC4', 'Sess_Type_Second single', 'Eth_Id_C_Hispanic']\n",
    "q2_columns=['HT', 'WT', 'BF', 'mLALC','ATE_C','TLFB90d_B', 'TAC_AUC','TAC_0toPeak',  'TAC3', 'Sess_Type_First Single', 'BIOSEX_0', 'Eth_Id_C_African/Af-Amer', 'Eth_Id_C_Caucasian', 'Eth_Id_C_Hispanic']\n",
    "model=LinearRegression()\n",
    "y=y2\n",
    "X_train=X[q2_columns].iloc[0:261]\n",
    "X_test=X[q2_columns].iloc[261].values.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sess_preds(X_train, y, X_test, q2_columns, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEPWISE REGRESSION WITHOUT INTERCEPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(X,x_columns,y):\n",
    "    X_OLS = X[x_columns]\n",
    "    results = sm.OLS(y, X_OLS).fit()\n",
    "    print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEPWISE REGRESSION WITH INTERCEPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_inter(X,x_columns,y):\n",
    "    X_OLS = X[x_columns]\n",
    "    X_OLS = sm.add_constant(X_OLS)\n",
    "    results = sm.OLS(y, X_OLS).fit()\n",
    "    print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORWARD/BACKWARD FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X_fb,y,model,feat_num,fb):\n",
    "    \n",
    "    sfs1 = sfs(model, k_features=feat_num, forward=fb, verbose=2, scoring='neg_mean_squared_error')\n",
    "    sfs1 = sfs1.fit(X_fb, y)\n",
    "    feat_names = list(sfs1.k_feature_names_)\n",
    "    print(feat_names)\n",
    "    plot_sfs(sfs1.get_metric_dict(), kind=None, figsize=(8, 8))\n",
    "    #plot_sfs(sfs1.get_metric_dict(), kind='std_err',figsize=(10, 10))\n",
    "    plt.ylabel('Negative MSE')\n",
    "    plt.xlabel('Number of features')\n",
    "    plt.title('Forward Feature Selection')\n",
    "    plt.grid()\n",
    "    plt.tight_layout() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_num=11\n",
    "fb=True\n",
    "X_fb=X[x_columns]\n",
    "y=y2\n",
    "model = LinearRegression()\n",
    "\n",
    "feature_selection(X_fb,y,model,feat_num,fb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN/TEST SET SPLIT AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tr_split(X_tt,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_tt, y, test_size = 0.20, random_state = 1)\n",
    "    lm = model.fit(X_train, y_train)\n",
    "    y_pred = lm.predict(X_test)\n",
    "    print(\"Train Set Mean Squared Error: \" ,mean_squared_error(y_train, lm.predict(X_train)))\n",
    "    print(\"Test Set Mean Sqaured Error: \", mean_squared_error(y_test, lm.predict(X_test)))\n",
    "    print(\"Train Set Mean Absolute Error: \" ,mean_absolute_error(y_train, lm.predict(X_train)))\n",
    "    print(\"Test Set Mean Absolute Error: \", mean_absolute_error(y_test, lm.predict(X_test)))\n",
    "    res = \"\\n\".join(\"{} {}\".format(x, y) for x, y in zip(y_test, y_pred))\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegression()\n",
    "X_tt=X[['BF', 'CAL_LUN', 'TLFB28d_F', 'Peak_TAC', 'TAC_AUC', 'TAC_0toPeak', 'TAC1', 'TAC3', 'TAC4', 'Eth_Id_C_Hispanic']]\n",
    "y=y1\n",
    "\n",
    "test_tr_split(X_tt,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-FOLD CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(X_cv,y,model):\n",
    "    cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    scores = cross_val_score(model, X_cv, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    print(scores)\n",
    "    print(scores.std())\n",
    "    print('Mean absolute error : ', mean(absolute(scores)))\n",
    "    scores = cross_val_score(model, X_cv, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "    print('Mean squared error : ', mean(absolute(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegression()\n",
    "X_cv=X[['WT', 'BF', 'VF', 'RM', 'TLFB90d_F', 'Peak_TAC', 'TAC_AUC', 'TAC1', 'TAC4', 'Sess_Type_Second single', 'Eth_Id_C_Hispanic']]\n",
    "y=y1\n",
    "\n",
    "cross_val(X_cv,y,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation fo estimating std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model by averaging performance across each fold\n",
    "\n",
    "def cv_for_std(X,y,model):\n",
    "\n",
    "    stdd = list()\n",
    "    ave_std = list()\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    for counter in range(10):\n",
    "        for train_ix, test_ix in kfold.split(X):\n",
    "            train_X, test_X = X.iloc[train_ix], X.iloc[test_ix]\n",
    "            train_y, test_y = y[train_ix], y[test_ix]\n",
    "            model.fit(train_X, train_y)\n",
    "            yhat = model.predict(test_X)\n",
    "            std= np.sqrt((sum((np.subtract(yhat,test_y))**2))/(len(yhat)-1))\n",
    "            stdd.append(std)\n",
    "            print('> ', std)\n",
    "        ave_std.append(mean(stdd))\n",
    "        stdd = list()\n",
    "    print('Average std for each round of CV:', ave_std)\n",
    "    print('Average std of the rounds of CV:', mean(ave_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y1\n",
    "model=LinearRegression()\n",
    "\n",
    "cv_for_std(X,y,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEARSON CORRELATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import heatmap\n",
    "\n",
    "corr = X.corr() \n",
    "\n",
    "plt.figure(figsize = (30, 30))\n",
    "heatmap(corr, cmap = 'coolwarm',annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOLDFELD-QUANDT HOMOSKEDASTICITY TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F         1.292044\n",
      "Prob>F    0.229485\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.stats.api as sms\n",
    "\n",
    "GQ_test = sms.diagnostic.het_goldfeldquandt(y1,X)\n",
    "df = pd.Series({'F':GQ_test[0], 'Prob>F':GQ_test[1]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, skew\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist(X,col):\n",
    "    sns.distplot(X[col], fit = norm, kde = True, color = 'blue')\n",
    "    plt.plot()\n",
    "    print('The skew of this distribution is = ', skew(X[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(array,y):\n",
    "    \n",
    "    global X_train, X_test, y_train, y_test, y_pred_tr, y_pred_test\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(array, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=1)\n",
    "    pprint(rf.get_params())\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = rf.predict(X_test)\n",
    "    y_pred_tr = rf.predict(X_train)\n",
    "    error_test = mean_absolute_error(y_test, y_pred_test) \n",
    "    error_tr = mean_absolute_error(y_train, y_pred_tr) \n",
    "    #mape_tr = 100 * (error_tr / y_train)\n",
    "    #mape_test = 100 * (error_test / y_test)\n",
    "    #accuracy_tr = 100 - np.mean(mape_tr)\n",
    "    #accuracy_test = 100 - np.mean(mape_test)\n",
    "\n",
    "    #print('R^2 :', rf.score(X_test, y_test))\n",
    "    #print('Accuracy training:', round(accuracy_tr, 2), '%.')\n",
    "    #print('Accuracy test:', round(accuracy_test, 2), '%.')\n",
    "\n",
    "    print('Mean Absolute Error Train:', error_tr)  \n",
    "    print('Mean Squared Error Train:', mean_squared_error(y_train, y_pred_tr))  \n",
    "    print('Mean Absolute Error Test:', error_test)  \n",
    "    print('Mean Squared Error Test:', mean_squared_error(y_test, y_pred_test))  \n",
    "    \n",
    "    feature_importances = list(zip(array, rf.feature_importances_))\n",
    "    feature_importances_ranked = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "    [print('Feature: {:35} Importance: {}'.format(*pair)) for pair in feature_importances_ranked];\n",
    "    \n",
    "    feature_names = [i[0] for i in feature_importances_ranked]\n",
    "    y_ticks = np.arange(0, len(feature_names))\n",
    "    x_axis = [i[1] for i in feature_importances_ranked]\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.barh(feature_names, x_axis)   \n",
    "    plt.title('Random Forest Feature Importance - q2',\n",
    "    fontdict= {'fontname':'Comic Sans MS','fontsize' : 20})\n",
    "    plt.ylabel('Features',fontdict= {'fontsize' : 16})\n",
    "    plt.show()\n",
    "    \n",
    "    result = permutation_importance(rf, X_train, y_train, n_repeats=10,random_state=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_meta_estimator(array,y):\n",
    "    global X_train, X_test, y_train, y_test, y_pred_tr, y_pred_test\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(array, y, test_size=0.2, random_state=1)\n",
    "    \n",
    "    rf = MultiOutputRegressor(RandomForestRegressor(random_state=1))\n",
    "    pprint(rf.get_params())\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = rf.predict(X_test)\n",
    "    y_pred_tr = rf.predict(X_train)\n",
    "    error_test = mean_absolute_error(y_test, y_pred_test) \n",
    "    error_tr = mean_absolute_error(y_train, y_pred_tr) \n",
    "    \n",
    "    print('Mean Absolute Error Train:', error_tr)  \n",
    "    print('Mean Squared Error Train:', mean_squared_error(y_train, y_pred_tr))  \n",
    "    print('Mean Absolute Error Test:', error_test)  \n",
    "    print('Mean Squared Error Test:', mean_squared_error(y_test, y_pred_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=X[['HT','WT','BF','VF','RM','WAIST','HIPS','AGE','mLALC','CAL_LUN','ATE_C','WATER_C','TLFB28d_F','TLFB90d_F','TLFB28d_B','TLFB90d_B','Sess_Type_Dual','Sess_Type_First Single','Sess_Type_Second single','Sess_Type_Steady','BIOSEX_0','Eth_Id_C_African/Af-Amer','Eth_Id_C_Asian','Eth_Id_C_Caucasian','Eth_Id_C_Hispanic','Eth_Id_C_Mixed']]\n",
    "y=y2\n",
    "\n",
    "random_forest(array,y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_categ_cols=['HT', 'WT', 'BF', 'VF', 'RM', 'WAIST', 'HIPS', 'AGE','CAL_LUN', 'ATE_C', 'WATER_C', 'TLFB90d_F','TLFB90d_B', 'Peak_TAC', 'TAC_Dur', 'TAC_AUC','TAC_0toPeak', 'TAC1', 'TAC2', 'TAC3', 'TAC4','BIOSEX_0'] \n",
    "array=X[no_categ_cols]\n",
    "y=y_biv\n",
    "\n",
    "random_forest(array,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Base model to tune\n",
    "rf = RandomForestRegressor(random_state=1)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=1, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print('Parameters of best model:\\n')\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "def evaluate(model, X_val, y_val):\n",
    "    predictions = model.predict(X_val)\n",
    "    errors = abs(predictions - y_val)\n",
    "    mape = 100 * np.mean(errors / y_val)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Absolute Percent Error = {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    print('Mean absolute error =', mean_absolute_error(y_val, predictions))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "base_model = RandomForestRegressor(n_estimators = 100, random_state = 1)\n",
    "base_model.fit(X_train, y_train)\n",
    "best_random = rf_random.best_estimator_\n",
    "\n",
    "print('Base model:')\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "print('Random search best model:')\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1, 2,3],\n",
    "    'min_samples_split': [1, 2, 3],\n",
    "    'n_estimators': [800, 1000, 1200, 1400, 1600]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Parameters of best model:\\n')\n",
    "print(grid_search.best_params_)\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test)\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import mean\n",
    "from numpy import absolute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN TEST SPLIT AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y1\n",
    "X_tt=X[['TAC_0toPeak','TAC1', 'TAC4','Sess_Type_Dual']]\n",
    "model = KNeighborsRegressor(n_neighbors=6, weights='distance')\n",
    "\n",
    "test_tr_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CROSS VALIDATION FOR DIFFERENT K VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_complexity_curve(k_list, knn_model, weight, X_cv, y):\n",
    "    \n",
    "    cv_scores = []\n",
    "    \n",
    "    for k in k_list:\n",
    "        knn = knn_model(k, weights=weight)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        scores = cross_val_score(knn, X_cv, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "        cv_scores.append(mean(absolute(scores)))\n",
    "    print(cv_scores)\n",
    "    print('CV smallest MSE: ', min(cv_scores))\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    ax.plot(k_list, cv_scores, label='Cross Validation MSE', color='black')\n",
    "    ax.set(title='k-NN with Different Values for $k$', xlabel='Number of Neighbors', ylabel='CV MSE')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.arange(1, 15)\n",
    "weight='distance'\n",
    "X_cv=X[['Peak_TAC','TAC_0toPeak', 'TAC1', 'TAC2', 'TAC4', 'Sess_Type_Dual']]\n",
    "y=y1\n",
    "\n",
    "plot_complexity_curve(neighbors, KNeighborsRegressor, weight, X_cv, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORWARD/BACKWARD FEATURE SELECTION (FIX K AND WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_num=3\n",
    "fb=False\n",
    "X_fb=X[x_columns]\n",
    "y=y2\n",
    "model = KNeighborsRegressor(n_neighbors=9, weights='uniform')\n",
    "\n",
    "feature_selection(X_fb,y,model,feat_num,fb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRID SEARCH FOR HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "print(KNeighborsRegressor().get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)\n",
    "parameters = {\"n_neighbors\": range(1, 15), \"weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print('Parameters of best model:\\n', gridsearch.best_params_)\n",
    "test_preds_grid = gridsearch.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, test_preds_grid)\n",
    "print('Test MSE: ', test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2','principal component 3', 'principal component 4'])\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=5)\n",
    "ldaReduction = lda.fit(X)\n",
    "ldaDf = pd.DataFrame(data = ldaReduction, columns = ['col1', 'col2','col3','col4','col5'])\n",
    "X_pca = pd.concat([ldaDf, df[['target']]], axis = 1)\n",
    "transformed = lda.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIVARIATE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSOR CHAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTIONS ON SPECIFIC SESSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order=[0,1]\n",
    "x_cols= ['CAL_LUN', 'Peak_TAC', 'TAC_0toPeak', 'TAC1', 'TAC3', 'TAC4', 'Sess_Type_Dual', 'BIOSEX_0']\n",
    "X_train=X[x_cols]\n",
    "X_test=X_test[x_cols]\n",
    "lm=LinearRegression()\n",
    "chain = RegressorChain(base_estimator=lm, order=order).fit(X_train, y_biv)\n",
    "chain.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORWARD/BACKWARD FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_num=8\n",
    "fb=True\n",
    "x_columns=[ 'HT', 'WT', 'BF', 'VF', 'RM', 'WAIST', 'HIPS', 'AGE', 'mLALC','CAL_LUN', 'ATE_C', 'WATER_C', 'TLFB28d_F', 'TLFB90d_F', 'TLFB28d_B','TLFB90d_B', 'Peak_TAC', 'TAC_Dur', 'TAC_AUC', 'TAC_0toPeak', 'TAC1','TAC2', 'TAC3', 'TAC4', 'Sess_Type_Dual', 'Sess_Type_First Single','Sess_Type_Second single', 'Sess_Type_Steady', 'BIOSEX_0','Eth_Id_C_African/Af-Amer', 'Eth_Id_C_Asian', 'Eth_Id_C_Caucasian','Eth_Id_C_Hispanic', 'Eth_Id_C_Mixed']\n",
    "X_fb=X[x_columns]\n",
    "y=y_biv\n",
    "lm=LinearRegression()\n",
    "ordr=[1,0]\n",
    "model=RegressorChain(base_estimator=lm, order=ordr)\n",
    "\n",
    "feature_selection(X_fb,y,model,feat_num,fb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-FOLD CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols=['TLFB28d_F', 'Peak_TAC', 'TAC_0toPeak', 'TAC1', 'TAC3', 'TAC4', 'Sess_Type_Second single', 'BIOSEX_0']\n",
    "X_cv=X[x_cols]\n",
    "y=y_biv\n",
    "order=[0,1]\n",
    "lm=LinearRegression()\n",
    "model = RegressorChain(base_estimator=lm, order=order)\n",
    "\n",
    "cross_val(X_cv,y,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install scikeras\n",
    "!pip install delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-FOLD CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel = Sequential()\n",
    "un=12\n",
    "input_d=len(X.columns)\n",
    "ep=30\n",
    "b_size=20\n",
    "\n",
    "nnmodel.add(Dense(units=un, input_dim=input_d, kernel_initializer='normal', activation='relu', kernel_regularizer=keras.regularizers.l2()))\n",
    "nnmodel.add(Dense(units=un, kernel_initializer='normal', activation='relu', kernel_regularizer=keras.regularizers.l2()))\n",
    "nnmodel.add(Dense(1, kernel_initializer='normal'))\n",
    "nnmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    " \n",
    "neural_network = KerasRegressor(build_fn=nnmodel, epochs=ep, batch_size=b_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns=['HT', 'WT', 'BF', 'VF', 'RM', 'WAIST', 'HIPS', 'AGE', 'mLALC','CAL_LUN', 'ATE_C', 'WATER_C', 'TLFB28d_F', 'TLFB90d_F', 'TLFB28d_B','TLFB90d_B', 'Peak_TAC', 'TAC_Dur', 'TAC_AUC', 'TAC_0toPeak', 'TAC1','TAC2', 'TAC3', 'TAC4', 'Sess_Type_Dual', 'Sess_Type_First Single','Sess_Type_Second single', 'Sess_Type_Steady', 'BIOSEX_0','Eth_Id_C_African/Af-Amer', 'Eth_Id_C_Asian', 'Eth_Id_C_Caucasian','Eth_Id_C_Hispanic', 'Eth_Id_C_Mixed']\n",
    "X_cv=X[x_columns]\n",
    "y=y1\n",
    "model=neural_network\n",
    "\n",
    "cross_val(X_cv,y,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOTSTRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful! Need to change the the index for X_boots_1 and X_boots 2 for different test episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boots(q1_covs,q2_covs,model,new_ind_num,new_ind):\n",
    "    \n",
    "    q1_preds=[]\n",
    "    q2_preds=[]\n",
    "    q1_preds_cut=[]\n",
    "    q2_preds_cut=[]\n",
    "\n",
    "    X_boots_1=X[q1_covs]\n",
    "    X_boots_2=X[q2_covs]\n",
    "    X_new_1=X_boots_1.iloc[new_ind_num]\n",
    "    X_new_2=X_boots_2.iloc[new_ind_num]\n",
    "    X_new_1=X_new_1.to_numpy().reshape(1,-1)\n",
    "    X_new_2=X_new_2.to_numpy().reshape(1,-1)\n",
    "    X_boots_1=X_boots_1.drop(new_ind)\n",
    "    X_boots_2=X_boots_2.drop(new_ind)\n",
    "    q1_boots=y1[1::]\n",
    "    q2_boots=y2[1::]\n",
    "\n",
    "    rows=len(X_boots_1.index)\n",
    "    sample=np.arange(start=0, stop=rows, step=1)\n",
    "    \n",
    "    #get 1000 q predictions using bootstrap \n",
    "    for iter in range(1000):\n",
    "        x = np.random.choice(sample, size=rows, replace=True)\n",
    "        X_train_1= X_boots_1.iloc[x]\n",
    "        X_train_2= X_boots_2.iloc[x]\n",
    "        q1_train= q1_boots[x]\n",
    "        q2_train= q2_boots[x]\n",
    "        lm_1 = model.fit(X_train_1, q1_train)\n",
    "        q1_preds.append(lm_1.predict(X_new_1)[0])\n",
    "        lm_2 = model.fit(X_train_2, q2_train)\n",
    "        q2_preds.append(lm_2.predict(X_new_2)[0])  \n",
    "    \n",
    "    #get 1000 q predictions using bootstrap to calculate confidence bounds\n",
    "    for iter in range(1000):\n",
    "        x = np.random.choice(sample, size=rows, replace=True)\n",
    "        X_train_1= X_boots_1.iloc[x]\n",
    "        X_train_2= X_boots_2.iloc[x]\n",
    "        q1_train= q1_boots[x]\n",
    "        q2_train= q2_boots[x]\n",
    "        lm_1 = model.fit(X_train_1, q1_train)\n",
    "        q1_preds_cut.append(lm_1.predict(X_new_1)[0])\n",
    "        lm_2 = model.fit(X_train_2, q2_train)\n",
    "        q2_preds_cut.append(lm_2.predict(X_new_2)[0])\n",
    "        \n",
    "    #get the q estimate when using the full training set\n",
    "    lm_1_true=model.fit(X_boots_1,q1_boots)\n",
    "    q1_true=lm_1_true.predict(X_new_1)\n",
    "    print(q1_true)\n",
    "    lm_2_true=model.fit(X_boots_2,q2_boots)\n",
    "    q2_true=lm_2_true.predict(X_new_2)\n",
    "    print(q2_true)\n",
    "    \n",
    "    savemat(\"q1_predictions.mat\", {\"q1_preds\": q1_preds})\n",
    "    savemat(\"q2_predictions.mat\", {\"q2_preds\": q2_preds})\n",
    "    savemat(\"q1_predictions_cut.mat\", {\"q1_preds_cut\": q1_preds_cut})\n",
    "    savemat(\"q2_predictions_cut.mat\", {\"q2_preds_cut\": q2_preds_cut})\n",
    "    savemat(\"q1_true.mat\",{\"q1_true\": q1_true})\n",
    "    savemat(\"q2_true.mat\",{\"q2_true\": q2_true})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_covs=['WT', 'BF', 'VF', 'RM', 'TLFB90d_F', 'Peak_TAC', 'TAC_AUC', 'TAC1', 'TAC4', 'Sess_Type_Second single', 'Eth_Id_C_Hispanic']\n",
    "q2_covs=['HT', 'WT', 'BF', 'mLALC', 'ATE_C', 'TLFB90d_B', 'TAC_AUC', 'TAC_0toPeak', 'TAC3', 'Sess_Type_First Single', 'BIOSEX_0', 'Eth_Id_C_African/Af-Amer', 'Eth_Id_C_Caucasian', 'Eth_Id_C_Hispanic']\n",
    "model=LinearRegression()\n",
    "new_ind='BT306_S4R'\n",
    "new_ind_num=0\n",
    "\n",
    "boots(q1_covs,q2_covs,model,new_ind_num,new_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "savemat(\"q1_predictions.mat\", {\"q1_preds\": q1_preds})\n",
    "savemat(\"q2_predictions.mat\", {\"q2_preds\": q2_preds})\n",
    "savemat(\"q1_predictions_cut.mat\", {\"q1_preds_cut\": q1_preds_cut})\n",
    "savemat(\"q2_predictions_cut.mat\", {\"q2_preds_cut\": q2_preds_cut})\n",
    "savemat(\"q1_true.mat\",{\"q1_true\": q1_true})\n",
    "savemat(\"q2_true.mat\",{\"q2_true\": q2_true})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTERING THE Qs USING KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge kneed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCALE THE Q VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kmeans=covariates[['q1','q2']]\n",
    "X_kmeans=X_kmeans.iloc[22::]\n",
    "#X_kmeans=X_kmeans[(X_kmeans['q1']<2.2) & (X_kmeans['q2']<2.5)]\n",
    "data_with_clusters = X_kmeans.copy()\n",
    "scaler = MinMaxScaler()\n",
    "X_kmeans['q1']= scaler.fit_transform(X_kmeans['q1'].values.reshape(-1, 1))\n",
    "X_kmeans['q2']= scaler.fit_transform(X_kmeans['q2'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY KMEANS AND CALCULATE THE PERCENTAGE OF EACH CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init=\"k-means++\", n_clusters=3, n_init=1000, max_iter=300, random_state=42)\n",
    "kmeans.fit(X_kmeans)\n",
    "identified_clusters = kmeans.fit_predict(X_kmeans)\n",
    "count_0 = len(identified_clusters[identified_clusters==0])\n",
    "count_1 = len(identified_clusters[identified_clusters==1])\n",
    "count_2 = len(identified_clusters[identified_clusters==2])\n",
    "pct_of_0 = count_0/(count_0+count_1+count_2)\n",
    "print(\"percentage of 0 cluster is\", pct_of_0*100)\n",
    "pct_of_1 = count_1/(count_0+count_1+count_2)\n",
    "print(\"percentage of 1 cluster\", pct_of_1*100)\n",
    "pct_of_2 = count_2/(count_0+count_1+count_2)\n",
    "print(\"percentage of 2 cluster\", pct_of_2*100)\n",
    "data_with_clusters['Clusters'] = identified_clusters \n",
    "plt.scatter(data_with_clusters['q1'],data_with_clusters['q2'],c=data_with_clusters['Clusters'],cmap='rainbow')\n",
    "plt.xlabel('q1')\n",
    "plt.ylabel('q2')\n",
    "print('The lowest SSE value:', kmeans.inertia_)\n",
    "print('Final locations of the centroid:', kmeans.cluster_centers_)\n",
    "print('The number of iterations required to converge:', kmeans.n_iter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE THE INDEXES FOR EACH CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "index_0=list(np.where(identified_clusters==0))[0]\n",
    "index_1=list(np.where(identified_clusters==1))[0]\n",
    "index_2=list(np.where(identified_clusters==2))[0]\n",
    "matlab_index=covariates['entry'].iloc[22::]\n",
    "index_0_mat=matlab_index[index_0].values\n",
    "index_1_mat=matlab_index[index_1].values\n",
    "index_2_mat=matlab_index[index_2].values\n",
    "savemat(\"index_0.mat\", {\"ind_0\": index_0_mat})\n",
    "savemat(\"index_1.mat\", {\"ind_1\": index_1_mat})\n",
    "savemat(\"index_2.mat\", {\"ind_2\": index_2_mat})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE THE Q VALUES WITH THE CORRESPONDING MATLAB INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_values=covariates[['entry','q1','q2']].iloc[22::].values\n",
    "savemat(\"q_values.mat\", {\"q_values\": q_values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE THE INDEXES OF THE FULL DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index_full=covariates.entry.iloc[22::].values\n",
    "savemat(\"train_ind_full.mat\", {\"tr_ind_full\": train_index_full})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST NUMBER OF CLUSTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELBOW METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_kwargs = {\n",
    "    \"init\": \"random\",\n",
    "    \"n_init\": 10,\n",
    "    \"max_iter\": 300,\n",
    "    \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "# A list holds the SSE values for each k\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(X_kmeans)\n",
    "    sse.append(kmeans.inertia_)\n",
    "    \n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(1, 11), sse)\n",
    "plt.xticks(range(1, 11))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()\n",
    "    \n",
    "kl = KneeLocator(range(1, 11), sse, curve=\"convex\", direction=\"decreasing\")\n",
    "kl.elbow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SILHOUETTE COEFFICIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list holds the silhouette coefficients for each k\n",
    "silhouette_coefficients = []\n",
    "# Notice you start at 2 clusters for silhouette coefficient\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(X_kmeans)\n",
    "    score = silhouette_score(X_kmeans, kmeans.labels_)\n",
    "    silhouette_coefficients.append(score)\n",
    "    \n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(2, 11), silhouette_coefficients)\n",
    "plt.xticks(range(2, 11))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINOMIAL/MULTINOMIAL LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OVERSAMPLING USING SMOTE, TRAIN THE MODEL AND EVALUATE ON TEST SESSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(db, drop_ind,data_with_clusters):\n",
    "\n",
    "    X_new=db[db['entry'].isin(drop_ind)].drop('entry',1)\n",
    "    y_train = data_with_clusters.Clusters[~data_with_clusters.index.isin(X_new.index)].values\n",
    "    X_train = X[~X.index.isin(X_new.index)].drop('entry',1)\n",
    "    os = SMOTE(random_state=1)\n",
    "    columns = X_train.columns\n",
    "    os_data_X,os_data_y=os.fit_sample(X_train, y_train)\n",
    "    os_data_X = pd.DataFrame(data=os_data_X,columns=columns)\n",
    "    os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "\n",
    "    print(\"length of oversampled data is \",len(os_data_X))\n",
    "    print(\"Number of 0 in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "    print(\"Number of 1 in oversampled data\",len(os_data_y[os_data_y['y']==1]))\n",
    "    print(\"Number of 2 in oversampled data\",len(os_data_y[os_data_y['y']==2]))\n",
    "    print(\"Proportion of 0 data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "    print(\"Proportion of 1 in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))\n",
    "    print(\"Proportion of 2 in oversampled data is \",len(os_data_y[os_data_y['y']==2])/len(os_data_X))\n",
    "    \n",
    "    return os_data_X, os_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=X\n",
    "drop_ind=[34, 50, 82]\n",
    "\n",
    "oversampling(db, drop_ind,data_with_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_data_y=os_data_y.values.ravel()\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=10000, penalty='none')\n",
    "model.fit(os_data_X, os_data_y)\n",
    "y_pred = model.predict(X_new)\n",
    "print('Predicted class:' , y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN/TEST SPLIT AND EVALUATION USING OVERSAMPLING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-FOLD CROSS VALIDATION MULTINOMIAL LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_log_reg_cv(X,y):\n",
    "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='none')\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_log_reg_cv(os_data_X,os_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-FOLD CROSS VALIDATION BINOMIAL LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_log_reg_cv(X,y):\n",
    "    model = LogisticRegression(solver='lbfgs', penalty='l2', C=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomial_log_reg_cv(os_data_X,os_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BINOMIAL LOGISTIC REGRESSION TRAIN/TEST SPLIT AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_tt(X_tt,y_tt,X_te,y_te):\n",
    "    model = LogisticRegression(solver='lbfgs', max_iter=1000, penalty='l2', C=1)\n",
    "    model.fit(X_tt, y_tt)\n",
    "    y_pred = model.predict(X_te)\n",
    "\n",
    "    res = \"\\n\".join(\"{} {}\".format(x, y) for x, y in zip(y_te, y_pred))\n",
    "    print(res)\n",
    "    print('Accuracy Score:', metrics.accuracy_score(y_te, y_pred)) \n",
    "    class_report=classification_report(y_te, y_pred)\n",
    "    print(class_report)\n",
    "    confusion_matrix(y_te, y_pred)\n",
    "    confmtrx = np.array(confusion_matrix(y_te, y_pred))\n",
    "    pd.DataFrame(confmtrx, index=['0','1'], columns=['predicted_0', 'predicted_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tt=os_data_X\n",
    "y_tt=os_data_y.values.ravel()\n",
    "X_te=X_test\n",
    "y_te=y_test.ravel()\n",
    "binomial_tt(X_tt,y_tt,X_te,y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTINOMIAL LOGISTIC REGRESIION TRAIN/TEST SPLIT AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_tt(X_tt,y_tt,X_te,y_te):\n",
    "    #y=identified_clusters \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 1)\n",
    "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, penalty='none')\n",
    "    model.fit(X_tt, y_tt)\n",
    "    y_pred = model.predict(X_te)\n",
    "\n",
    "    res = \"\\n\".join(\"{} {}\".format(x, y) for x, y in zip(y_te, y_pred))\n",
    "    print(res)\n",
    "    print('Accuracy Score:', metrics.accuracy_score(y_te, y_pred)) \n",
    "    class_report=classification_report(y_te, y_pred)\n",
    "    print(class_report)\n",
    "    confusion_matrix(y_te, y_pred)\n",
    "    confmtrx = np.array(confusion_matrix(y_te, y_pred))\n",
    "    print(pd.DataFrame(confmtrx, index=['0','1','2'], columns=['predicted_0', 'predicted_1','predicted_2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tt=os_data_X\n",
    "y_tt=os_data_y.values.ravel()\n",
    "X_te=X_test\n",
    "y_te=y_test.ravel()\n",
    "multinomial_tt(X_tt,y_tt,X_te,y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTINOMIAL LOGISTIC REGRESSION TUNE FOR THE WEIGHTING OF PENALTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    for p in [0.0, 0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
    "        key = '%.4f' % p\n",
    "        if p == 0.0:\n",
    "            models[key] = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='none')\n",
    "        else:\n",
    "            models[key] = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', C=p)\n",
    "    return models\n",
    " \n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    " \n",
    "models = get_models()\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, os_data_X, os_data_y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTINOMIAL LOGISTIC REGRESSION TUNE FOR THE WEIGHTING OF PENALTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    for p in [0.0, 0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
    "        key = '%.4f' % p\n",
    "        if p == 0:\n",
    "            models[key] = LogisticRegression(solver='lbfgs', penalty='none')\n",
    "        else:\n",
    "            models[key] = LogisticRegression(solver='lbfgs', penalty='l2', C=p)\n",
    "    return models\n",
    " \n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    " \n",
    "models = get_models()\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, os_data_X, os_data_y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN/TEST SPLIT AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_tt(X_tt,y_tt,X_te,y_te,k,weight):\n",
    "    model = KNeighborsClassifier(n_neighbors = k, weights=weight)\n",
    "    model.fit(X_tt, y_tt)\n",
    "    y_pred = model.predict(X_te)\n",
    "\n",
    "    res = \"\\n\".join(\"{} {}\".format(x, y) for x, y in zip(y_te, y_pred))\n",
    "    print(res)\n",
    "    print('Accuracy Score:', metrics.accuracy_score(y_te, y_pred)) \n",
    "    class_report=classification_report(y_te, y_pred)\n",
    "    print(class_report)\n",
    "    confusion_matrix(y_te, y_pred)\n",
    "    confmtrx = np.array(confusion_matrix(y_te, y_pred))\n",
    "    print(pd.DataFrame(confmtrx, index=['0','1','2'], columns=['predicted_0', 'predicted_1','predicted_2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tt=os_data_X\n",
    "y_tt=os_data_y.values.ravel()\n",
    "X_te=X_test\n",
    "y_te=y_test.ravel()\n",
    "\n",
    "KNN_tt(X_tt,y_tt,X_te,y_te,11,'distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-FOLD CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classification_cv(X_cv,y_cv,k,weight):\n",
    "    model = KNeighborsClassifier(n_neighbors = k, weights=weight)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(model, X_cv, y_cv, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_classification_cv(os_data_X, os_data_y,11,'distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPLEXITY CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_complexity_curve_classification(k_list, knn_model, weight, X_cv, y_cv):\n",
    "    \n",
    "    cv_scores = []\n",
    "    \n",
    "    for k in k_list:\n",
    "        knn = knn_model(k, weights=weight)\n",
    "        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "        scores = cross_val_score(knn, X_cv, y_cv, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "        cv_scores.append(mean(scores))\n",
    "    \n",
    "    print('CV Largest Accuracy: ', max(cv_scores))\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    ax.plot(k_list, cv_scores, label='Cross Validation Accuracy', color='black')\n",
    "    ax.set(title='k-NN with Different Values for $k$', xlabel='Number of Neighbors', ylabel='CV Accuracy')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.arange(1, 15)\n",
    "weight='distance'\n",
    "\n",
    "plot_complexity_curve_classification(neighbors, KNeighborsClassifier, weight, os_data_X, os_data_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
